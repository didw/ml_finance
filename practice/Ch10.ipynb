{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pyfolio as pf\n",
    "\n",
    "sys.path.insert(0, '/mnt/afml/ml_finance/mlfinlab')\n",
    "from mlfinlab.data_structures import imbalance_data_structures as imbar, standard_data_structures as bar\n",
    "import mlfinlab as ml\n",
    "\n",
    "sys.path.insert(0, '/mnt/afml/ml_finance/finance_ml')\n",
    "from finance_ml import sampling, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parq(fname):\n",
    "    table = pq.read_table(fname)\n",
    "    df = table.to_pandas()\n",
    "    df = df.set_index('TIMESTAMP')\n",
    "    ''' 중복된 index 제거, volume은 더해준다 '''\n",
    "    df = df.sort_values(by='TIMESTAMP')  # 중복 데이터 무시\n",
    "    df_v = df.groupby(df.index).sum()\n",
    "    df = df.loc[~df.index.duplicated(keep='first')]\n",
    "    df['V'] = df_v['V']\n",
    "    df['DV'] = df_v['DV']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'dataset/TRADE_A233740_2018.parq'\n",
    "df = load_parq(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dollar bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'dataset/TRADE_A233740_2018.csv'\n",
    "bar_fname = 'dataset/DBAR_A233740_2018.csv'\n",
    "if not os.path.exists(fname):\n",
    "    df_csv = df.reset_index()[['TIMESTAMP', 'PRICE', 'V']]\n",
    "    df_csv.columns = ['date_time', 'price', 'volume']\n",
    "    df_csv['price'] = df_csv['price'].astype('float')\n",
    "    df_csv.to_csv(fname, index=False)\n",
    "    \n",
    "if os.path.exists(bar_fname):\n",
    "    dbar = pd.read_csv(bar_fname, index_col='date_time')\n",
    "    dbar.index = pd.to_datetime(dbar.index)\n",
    "else:\n",
    "    dbar = bar.get_dollar_bars(fname, threshold=1e8)\n",
    "    dbar.index = pd.to_datetime(dbar.index)\n",
    "    dbar.to_csv(bar_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7647271, 5)\n",
      "(518545, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(dbar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars(df, df_bar, desc='bar'):\n",
    "    plt.figure(figsize = (18, 8))\n",
    "    plt.title('Bars over the prices')\n",
    "    plt.plot(df.index, df['PRICE'], label = 'Raw prices', color = 'blue')\n",
    "    plt.plot(df_bar.index, df_bar['close'], ls = '', markersize = 5, marker = 'o', color = 'red', label = desc)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_co_events(d0, df, t_barrier_events, num_co_events, avg_uniq): \n",
    "    df0 = df.loc[d0]\n",
    "    t_barrier_events0 = t_barrier_events.loc[d0]\n",
    "    num_co_events0 = num_co_events.loc[d0]\n",
    "    avg_uniq0 = avg_uniq.loc[d0]\n",
    "    \n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    plt.title('Triple barriers over the prices')\n",
    "    plt.plot(df0.index.values, df0.close.values, label='raw_prices', ls='--', color='black')\n",
    "\n",
    "    # Draw barrier region \n",
    "    for i in t_barrier_events0.itertuples(): \n",
    "        try: \n",
    "            t0, t1, trgt = i.Index, i.t1, i.trgt\n",
    "            t1 = min(t1, pd.Timestamp(\"{} 15:30\".format(d0)))\n",
    "\n",
    "            x0 = mdates.date2num(t0)\n",
    "            x1 = mdates.date2num(t1)\n",
    "            w = x1 - x0 \n",
    "\n",
    "            y0 = df0.loc[t0].close * (1 - trgt)\n",
    "            y1 = df0.loc[t0].close * (1 + trgt)\n",
    "            h = y1 - y0\n",
    "\n",
    "            rect = Rectangle((x0, y0), w, h, color='black', alpha=0.05)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "            df1 = df0.loc[[t0, t1]].dropna()\n",
    "\n",
    "            plt.plot(df1.index.values, df1.close.values, label='triple barrier', ls='--', color='red')\n",
    "            if df1.shape[0] >= 2:\n",
    "                plt.scatter(df1.index.values[1], df1.close.values[1], marker='o', linewidths=5, color='red')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    plt.show()\n",
    "    \n",
    "    # Draw num of co-events\n",
    "    num_co_events0.plot(kind='bar', figsize=(30,10), label='DV')\n",
    "    plt.show()\n",
    "    \n",
    "    # Draw average uniqueness\n",
    "    avg_uniq0.plot(kind='bar', figsize=(30,10), label='AvgUniqueness')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df[df.index>datetime.datetime(2018,5,23,9,0)]\n",
    "df_sub = df_sub[df_sub.index<datetime.datetime(2018,5,24,9,0)]\n",
    "dbar_sub = dbar[dbar.index>datetime.datetime(2018,5,23,9,0)]\n",
    "dbar_sub = dbar_sub[dbar_sub.index<datetime.datetime(2018,5,24,9,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply triple barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.log(dbar['close']).diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2018-01-03 09:00:21.481000')\n"
     ]
    }
   ],
   "source": [
    "# Compute daily volatility\n",
    "daily_vol = ml.util.get_daily_vol(close=dbar['close'], lookback=50)\n",
    "\n",
    "# Apply Symmetric CUSUM Filter and get timestamps for events\n",
    "# Note: Only the CUSUM filter needs a point estimate for volatility\n",
    "daily_vol_mean = daily_vol.rolling(10000).mean()\n",
    "cusum_events = ml.filters.cusum_filter(dbar['close'], daily_vol_mean=daily_vol_mean)\n",
    "\n",
    "# Compute vertical barrier\n",
    "vertical_barriers = ml.labeling.add_vertical_barrier(t_events=cusum_events, close=dbar['close'], num_days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary - Build Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 21:13:40.429151 100.0% apply_pt_sl_on_t1 done after 0.02 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "pt_sl = [1, 2]\n",
    "min_ret = 0.01\n",
    "triple_barrier_events = ml.labeling.get_events(close=dbar['close'],\n",
    "                                               t_events=cusum_events,\n",
    "                                               pt_sl=pt_sl,\n",
    "                                               target=daily_vol,\n",
    "                                               min_ret=min_ret,\n",
    "                                               num_threads=3,\n",
    "                                               vertical_barrier_times=vertical_barriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_p = ml.labeling.get_bins(triple_barrier_events, dbar['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    334\n",
       " 1    283\n",
       " 0    136\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_p.bin.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dbar.copy()\n",
    "\n",
    "# Log Returns\n",
    "raw_data['log_ret'] = np.log(raw_data['close']).diff()\n",
    "\n",
    "# Momentum\n",
    "raw_data['mom1'] = raw_data['close'].pct_change(periods=1)\n",
    "raw_data['mom2'] = raw_data['close'].pct_change(periods=2)\n",
    "raw_data['mom5'] = raw_data['close'].pct_change(periods=5)\n",
    "\n",
    "# Volatility\n",
    "raw_data['volatility_50'] = raw_data['log_ret'].rolling(window=50, min_periods=50, center=False).std()\n",
    "raw_data['volatility_15'] = raw_data['log_ret'].rolling(window=15, min_periods=15, center=False).std()\n",
    "\n",
    "# Serial Correlation (Takes about 4 minutes)\n",
    "window_autocorr = 50\n",
    "\n",
    "raw_data['autocorr_1'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=1), raw=False)\n",
    "raw_data['autocorr_3'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=3), raw=False)\n",
    "\n",
    "# Get the various log -t returns\n",
    "raw_data['log_t1'] = raw_data['log_ret'].shift(1)\n",
    "raw_data['log_t2'] = raw_data['log_ret'].shift(2)\n",
    "raw_data['log_t5'] = raw_data['log_ret'].shift(5)\n",
    "\n",
    "# Remove look ahead bias\n",
    "raw_data = raw_data.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features at event dates\n",
    "X = raw_data\n",
    "\n",
    "# Drop unwanted columns\n",
    "try:\n",
    "    X.drop(['open', 'high', 'low', 'close', 'volume'], axis=1, inplace=True)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "X.dropna(inplace=True)\n",
    "y = labels_p['bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_idx = y.index.join(X.index).join(labels_p.index)\n",
    "X = X.loc[com_idx]\n",
    "y = y.loc[com_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary - Balance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "X_training_validation = X['2018-01-01':'2018-10-31']\n",
    "y_training_validation = y['2018-01-01':'2018-10-31']\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_training_validation, y_training_validation, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary - Fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimator = 10\n",
    "depth = 2\n",
    "c_random_state = 42\n",
    "\n",
    "# Refit a new model with best params, so we can see feature importance\n",
    "rf1 = RandomForestClassifier(max_depth=depth, n_estimators=n_estimator,\n",
    "                            criterion='entropy', random_state=c_random_state)\n",
    "\n",
    "rf1.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"['open' 'high' 'low' 'close' 'volume'] not found in axis\"\n"
     ]
    }
   ],
   "source": [
    "X = raw_data\n",
    "X.dropna(inplace=True)\n",
    "try:\n",
    "    X.drop(['open', 'high', 'low', 'close', 'volume'], axis=1, inplace=True)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predict = rf1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbar2 = dbar.loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbar2['side'] = total_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 21:26:04.528682 100.0% apply_pt_sl_on_t1 done after 0.1 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "pt_sl = [1, 2]\n",
    "min_ret = 0.005\n",
    "triple_barrier_events = ml.labeling.get_events(close=dbar2['close'],\n",
    "                                               t_events=cusum_events,\n",
    "                                               pt_sl=pt_sl,\n",
    "                                               target=daily_vol,\n",
    "                                               min_ret=min_ret,\n",
    "                                               num_threads=3,\n",
    "                                               vertical_barrier_times=vertical_barriers,\n",
    "                                               side_prediction=dbar2['side'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>side</th>\n",
       "      <th>t1</th>\n",
       "      <th>trgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:01:09.291</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:53.717</td>\n",
       "      <td>0.005417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:01:32.046</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:38.938</td>\n",
       "      <td>0.005706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:02:03.804</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:53.717</td>\n",
       "      <td>0.005768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:02:29.405</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:55.275</td>\n",
       "      <td>0.005546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:02:46.421</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:03:00.761</td>\n",
       "      <td>0.005789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         side                      t1      trgt\n",
       "2018-01-09 09:01:09.291  -1.0 2018-01-09 09:02:53.717  0.005417\n",
       "2018-01-09 09:01:32.046  -1.0 2018-01-09 09:02:38.938  0.005706\n",
       "2018-01-09 09:02:03.804  -1.0 2018-01-09 09:02:53.717  0.005768\n",
       "2018-01-09 09:02:29.405  -1.0 2018-01-09 09:02:55.275  0.005546\n",
       "2018-01-09 09:02:46.421  -1.0 2018-01-09 09:03:00.761  0.005789"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triple_barrier_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    2392\n",
       " 1.0    1225\n",
       "Name: side, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_m = ml.labeling.get_bins(triple_barrier_events, dbar2['close'])\n",
    "labels_m.side.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2261\n",
       "0    1356\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_m.bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels_m['bin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta - Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_idx = y.index.join(X.index).join(labels_m.index)\n",
    "X = X.loc[com_idx]\n",
    "y = y.loc[com_idx]\n",
    "labels_m = labels_m.loc[com_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "X_training_validation = X['2018-01-01':'2018-10-31']\n",
    "y_training_validation = y['2018-01-01':'2018-10-31']\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_training_validation, y_training_validation, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta - Balance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "X_training_validation = X['2018-01-01':'2018-10-31']\n",
    "y_training_validation = y['2018-01-01':'2018-10-31']\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_training_validation, y_training_validation, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1577\n",
       "0     927\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([y_train, X_train], axis=1, join='inner')\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    927\n",
       "0    927\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsample the training data to have a 50 - 50 split\n",
    "# https://elitedatascience.com/imbalanced-classes\n",
    "majority = train_df[train_df['bin'] == 0]\n",
    "minority = train_df[train_df['bin'] == 1]\n",
    "\n",
    "new_minority = resample(minority, \n",
    "                   replace=True,     # sample with replacement\n",
    "                   n_samples=majority.shape[0],    # to match majority class\n",
    "                   random_state=42)\n",
    "\n",
    "train_df = pd.concat([majority, new_minority])\n",
    "train_df = shuffle(train_df, random_state=42)\n",
    "\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta - Fit a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit a new model with best params, so we can see feature importance\n",
    "rf2 = RandomForestClassifier(max_depth=depth, n_estimators=n_estimator,\n",
    "                            criterion='entropy', random_state=c_random_state)\n",
    "\n",
    "rf2.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bet Sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finance_ml.labeling.sizes import get_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = rf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37042055, 0.62957945],\n",
       "       [0.33056842, 0.66943158],\n",
       "       [0.37042055, 0.62957945],\n",
       "       ...,\n",
       "       [0.37042055, 0.62957945],\n",
       "       [0.37042055, 0.62957945],\n",
       "       [0.39005255, 0.60994745]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.Series(y_prob[:,1], index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>side</th>\n",
       "      <th>t1</th>\n",
       "      <th>trgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:01:09.291</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:53.717</td>\n",
       "      <td>0.005417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:01:32.046</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:38.938</td>\n",
       "      <td>0.005706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:02:03.804</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:53.717</td>\n",
       "      <td>0.005768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:02:29.405</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:55.275</td>\n",
       "      <td>0.005546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:02:46.421</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:03:00.761</td>\n",
       "      <td>0.005789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         side                      t1      trgt\n",
       "2018-01-09 09:01:09.291  -1.0 2018-01-09 09:02:53.717  0.005417\n",
       "2018-01-09 09:01:32.046  -1.0 2018-01-09 09:02:38.938  0.005706\n",
       "2018-01-09 09:02:03.804  -1.0 2018-01-09 09:02:53.717  0.005768\n",
       "2018-01-09 09:02:29.405  -1.0 2018-01-09 09:02:55.275  0.005546\n",
       "2018-01-09 09:02:46.421  -1.0 2018-01-09 09:03:00.761  0.005789"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triple_barrier_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'t1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/mnt/afml/venv/lib/python3.5/site-packages/pandas/core/indexes/base.py\", line 4381, in get_value\n    return libindex.get_value_box(s, key)\n  File \"pandas/_libs/index.pyx\", line 52, in pandas._libs.index.get_value_box\n  File \"pandas/_libs/index.pyx\", line 48, in pandas._libs.index.get_value_at\n  File \"pandas/_libs/util.pxd\", line 113, in pandas._libs.util.get_value_at\n  File \"pandas/_libs/util.pxd\", line 98, in pandas._libs.util.validate_indexer\nTypeError: 'str' object cannot be interpreted as an integer\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/mnt/afml/venv/lib/python3.5/site-packages/pandas/core/indexes/datetimes.py\", line 946, in get_value\n    return com.maybe_box(self, Index.get_value(self, series, key),\n  File \"/mnt/afml/venv/lib/python3.5/site-packages/pandas/core/indexes/base.py\", line 4389, in get_value\n    raise e1\n  File \"/mnt/afml/venv/lib/python3.5/site-packages/pandas/core/indexes/base.py\", line 4375, in get_value\n    tz=getattr(series.dtype, 'tz', None))\n  File \"pandas/_libs/index.pyx\", line 81, in pandas._libs.index.IndexEngine.get_value\n  File \"pandas/_libs/index.pyx\", line 89, in pandas._libs.index.IndexEngine.get_value\n  File \"pandas/_libs/index.pyx\", line 449, in pandas._libs.index.DatetimeEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 455, in pandas._libs.index.DatetimeEngine._date_check_type\nKeyError: 't1'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/mnt/afml/venv/lib/python3.5/site-packages/pandas/core/indexes/datetimes.py\", line 956, in get_value\n    return self.get_value_maybe_box(series, key)\n  File \"/mnt/afml/venv/lib/python3.5/site-packages/pandas/core/indexes/datetimes.py\", line 969, in get_value_maybe_box\n    key = Timestamp(key)\n  File \"pandas/_libs/tslibs/timestamps.pyx\", line 748, in pandas._libs.tslibs.timestamps.Timestamp.__new__\n  File \"pandas/_libs/tslibs/conversion.pyx\", line 288, in pandas._libs.tslibs.conversion.convert_to_tsobject\n  File \"pandas/_libs/tslibs/conversion.pyx\", line 489, in pandas._libs.tslibs.conversion.convert_str_to_tsobject\n  File \"pandas/_libs/tslibs/conversion.pyx\", line 311, in pandas._libs.tslibs.conversion.convert_to_tsobject\n  File \"pandas/_libs/tslibs/conversion.pyx\", line 391, in pandas._libs.tslibs.conversion.convert_datetime_to_tsobject\n  File \"pandas/_libs/tslibs/np_datetime.pyx\", line 120, in pandas._libs.tslibs.np_datetime.check_dts_bounds\npandas._libs.tslibs.np_datetime.OutOfBoundsDatetime: Out of bounds nanosecond timestamp: 1-01-01 00:00:00\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/mnt/afml/ml_finance/finance_ml/finance_ml/multiprocessing/utils.py\", line 12, in expand_call\n    out = func(**kwargs)\n  File \"/mnt/afml/ml_finance/finance_ml/finance_ml/labeling/sizes.py\", line 67, in mp_avg_active_signals\n    (loc < signals['t1']) | pd.isnull(signals['t1']))\n  File \"/mnt/afml/venv/lib/python3.5/site-packages/pandas/core/series.py\", line 868, in __getitem__\n    result = self.index.get_value(self, key)\n  File \"/mnt/afml/venv/lib/python3.5/site-packages/pandas/core/indexes/datetimes.py\", line 958, in get_value\n    raise KeyError(key)\nKeyError: 't1'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-9aaa07ba7474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbet_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriple_barrier_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/afml/ml_finance/finance_ml/finance_ml/labeling/sizes.py\u001b[0m in \u001b[0;36mget_signal\u001b[0;34m(prob, events, scale, step_size, num_classes, num_threads, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'side'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'side'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_active_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscrete_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/afml/ml_finance/finance_ml/finance_ml/labeling/sizes.py\u001b[0m in \u001b[0;36mavg_active_signals\u001b[0;34m(signals, num_threads, timestamps)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mmp_avg_active_signals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'molecule'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mnum_threads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         signals=signals)\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/afml/ml_finance/finance_ml/finance_ml/multiprocessing/pandas.py\u001b[0m in \u001b[0;36mmp_pandas_obj\u001b[0;34m(func, pd_obj, num_threads, mp_batches, linear_mols, descend, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;31m# You can use either of pd.Series or pd.DatFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/afml/ml_finance/finance_ml/finance_ml/multiprocessing/utils.py\u001b[0m in \u001b[0;36mprocess_jobs\u001b[0;34m(jobs, task, num_threads)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mtime0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Execute programs here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mreport_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 't1'"
     ]
    }
   ],
   "source": [
    "bet_size = get_signal(y_df, triple_barrier_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bs(df, bs, desc='bet_size'):\n",
    "    fig, ax1 = plt.subplots(figsize=(18,10))\n",
    "    plt.title('Bet size over the prices')\n",
    "    ax1.plot(df.index, df['close'], label = 'Raw prices', color = 'blue')\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(bs.index, bs, ls = '', markersize = 10, marker='o', color = 'red', label = desc)\n",
    "    fig.figsizes = (18,10)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_date = '2018-02-13'\n",
    "triple_barrier_events.loc[plot_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_date = '2018-02-13'\n",
    "plot_bs(dbar.loc[plot_date], bet_size.loc[plot_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_date = '2018-05-15'\n",
    "plot_bs(dbar.loc[plot_date], bet_size.loc[plot_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_date = '2018-07-12'\n",
    "plot_bs(dbar.loc[plot_date], bet_size.loc[plot_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betSize(w,x): \n",
    "    return x*(w+x**2)**-.5\n",
    "#——————————————————————————————————————— \n",
    "def getTPos(w,f,mP,maxPos): \n",
    "    return int(betSize(w,f-mP)*maxPos) \n",
    "#——————————————————————————————————————— \n",
    "def invPrice(f,w,m): \n",
    "    return f-m*(w/(1-m**2))**.5\n",
    "#——————————————————————————————————————— \n",
    "def limitPrice(tPos,pos,f,w,maxPos): \n",
    "    sgn=(1 if tPos>=pos else -1) \n",
    "    lP=0 \n",
    "    for j in range(abs(pos+sgn),abs(tPos+1)): \n",
    "        lP+=invPrice(f,w,j/float(maxPos))\n",
    "    lP/=tPos-pos \n",
    "    return lP\n",
    "#——————————————————————————————————————— \n",
    "def getW(x,m): \n",
    "    # 0<alpha<1 \n",
    "    return x**2*(m**-2-1)\n",
    "#——————————————————————————————————————— \n",
    "\n",
    "pos,maxPos,mP,f,wParams=0,100,100,115,{'divergence':10,'m':.95} \n",
    "# calibrate w \n",
    "w=getW(wParams['divergence'],wParams['m']) \n",
    "print(w)\n",
    "# get tPos \n",
    "tPos=getTPos(w,f,mP,maxPos) \n",
    "print(tPos)\n",
    "# limit price for order return\n",
    "lP=limitPrice(tPos,pos,f,w,maxPos) \n",
    "print(lP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afml",
   "language": "python",
   "name": "afml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
