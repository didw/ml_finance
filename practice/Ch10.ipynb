{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/afml/venv/lib/python3.5/site-packages/pyfolio/pos.py:28: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  ' to position notionals.'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pyfolio as pf\n",
    "\n",
    "sys.path.insert(0, '/mnt/afml/ml_finance/mlfinlab')\n",
    "from mlfinlab.data_structures import imbalance_data_structures as imbar, standard_data_structures as bar\n",
    "import mlfinlab as ml\n",
    "\n",
    "sys.path.insert(0, '/mnt/afml/ml_finance/finance_ml')\n",
    "from finance_ml import sampling, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parq(fname):\n",
    "    table = pq.read_table(fname)\n",
    "    df = table.to_pandas()\n",
    "    df = df.set_index('TIMESTAMP')\n",
    "    ''' 중복된 index 제거, volume은 더해준다 '''\n",
    "    df = df.sort_values(by='TIMESTAMP')  # 중복 데이터 무시\n",
    "    df_v = df.groupby(df.index).sum()\n",
    "    df = df.loc[~df.index.duplicated(keep='first')]\n",
    "    df['V'] = df_v['V']\n",
    "    df['DV'] = df_v['DV']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'dataset/TRADE_A233740_2018.parq'\n",
    "df = load_parq(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dollar bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'dataset/TRADE_A233740_2018.csv'\n",
    "bar_fname = 'dataset/DBAR_A233740_2018.csv'\n",
    "if not os.path.exists(fname):\n",
    "    df_csv = df.reset_index()[['TIMESTAMP', 'PRICE', 'V']]\n",
    "    df_csv.columns = ['date_time', 'price', 'volume']\n",
    "    df_csv['price'] = df_csv['price'].astype('float')\n",
    "    df_csv.to_csv(fname, index=False)\n",
    "    \n",
    "if os.path.exists(bar_fname):\n",
    "    dbar = pd.read_csv(bar_fname, index_col='date_time')\n",
    "    dbar.index = pd.to_datetime(dbar.index)\n",
    "else:\n",
    "    dbar = bar.get_dollar_bars(fname, threshold=1e8)\n",
    "    dbar.index = pd.to_datetime(dbar.index)\n",
    "    dbar.to_csv(bar_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7647271, 5)\n",
      "(518545, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(dbar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars(df, df_bar, desc='bar'):\n",
    "    plt.figure(figsize = (18, 8))\n",
    "    plt.title('Bars over the prices')\n",
    "    plt.plot(df.index, df['PRICE'], label = 'Raw prices', color = 'blue')\n",
    "    plt.plot(df_bar.index, df_bar['close'], ls = '', markersize = 5, marker = 'o', color = 'red', label = desc)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_co_events(d0, df, t_barrier_events, num_co_events, avg_uniq): \n",
    "    df0 = df.loc[d0]\n",
    "    t_barrier_events0 = t_barrier_events.loc[d0]\n",
    "    num_co_events0 = num_co_events.loc[d0]\n",
    "    avg_uniq0 = avg_uniq.loc[d0]\n",
    "    \n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    plt.title('Triple barriers over the prices')\n",
    "    plt.plot(df0.index.values, df0.close.values, label='raw_prices', ls='--', color='black')\n",
    "\n",
    "    # Draw barrier region \n",
    "    for i in t_barrier_events0.itertuples(): \n",
    "        try: \n",
    "            t0, t1, trgt = i.Index, i.t1, i.trgt\n",
    "            t1 = min(t1, pd.Timestamp(\"{} 15:30\".format(d0)))\n",
    "\n",
    "            x0 = mdates.date2num(t0)\n",
    "            x1 = mdates.date2num(t1)\n",
    "            w = x1 - x0 \n",
    "\n",
    "            y0 = df0.loc[t0].close * (1 - trgt)\n",
    "            y1 = df0.loc[t0].close * (1 + trgt)\n",
    "            h = y1 - y0\n",
    "\n",
    "            rect = Rectangle((x0, y0), w, h, color='black', alpha=0.05)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "            df1 = df0.loc[[t0, t1]].dropna()\n",
    "\n",
    "            plt.plot(df1.index.values, df1.close.values, label='triple barrier', ls='--', color='red')\n",
    "            if df1.shape[0] >= 2:\n",
    "                plt.scatter(df1.index.values[1], df1.close.values[1], marker='o', linewidths=5, color='red')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    plt.show()\n",
    "    \n",
    "    # Draw num of co-events\n",
    "    num_co_events0.plot(kind='bar', figsize=(30,10), label='DV')\n",
    "    plt.show()\n",
    "    \n",
    "    # Draw average uniqueness\n",
    "    avg_uniq0.plot(kind='bar', figsize=(30,10), label='AvgUniqueness')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df[df.index>datetime.datetime(2018,5,23,9,0)]\n",
    "df_sub = df_sub[df_sub.index<datetime.datetime(2018,5,24,9,0)]\n",
    "dbar_sub = dbar[dbar.index>datetime.datetime(2018,5,23,9,0)]\n",
    "dbar_sub = dbar_sub[dbar_sub.index<datetime.datetime(2018,5,24,9,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply triple barrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.log(dbar['close']).diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2018-01-03 09:00:21.481000')\n"
     ]
    }
   ],
   "source": [
    "# Compute daily volatility\n",
    "daily_vol = ml.util.get_daily_vol(close=dbar['close'], lookback=50)\n",
    "\n",
    "# Apply Symmetric CUSUM Filter and get timestamps for events\n",
    "# Note: Only the CUSUM filter needs a point estimate for volatility\n",
    "daily_vol_mean = daily_vol.rolling(10000).mean()\n",
    "cusum_events = ml.filters.cusum_filter(dbar['close'], daily_vol_mean=daily_vol_mean)\n",
    "\n",
    "# Compute vertical barrier\n",
    "vertical_barriers = ml.labeling.add_vertical_barrier(t_events=cusum_events, close=dbar['close'], num_days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary - Build Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-15 17:25:29.306077 100.0% apply_pt_sl_on_t1 done after 0.1 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "pt_sl = [1, 2]\n",
    "min_ret = 0.005\n",
    "triple_barrier_events = ml.labeling.get_events(close=dbar['close'],\n",
    "                                               t_events=cusum_events,\n",
    "                                               pt_sl=pt_sl,\n",
    "                                               target=daily_vol,\n",
    "                                               min_ret=min_ret,\n",
    "                                               num_threads=3,\n",
    "                                               vertical_barrier_times=vertical_barriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_p = ml.labeling.get_bins(triple_barrier_events, dbar['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1727\n",
       " 1    1679\n",
       " 0     211\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_p.bin.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dbar.copy()\n",
    "\n",
    "# Log Returns\n",
    "raw_data['log_ret'] = np.log(raw_data['close']).diff()\n",
    "\n",
    "# Momentum\n",
    "raw_data['mom1'] = raw_data['close'].pct_change(periods=1)\n",
    "raw_data['mom2'] = raw_data['close'].pct_change(periods=2)\n",
    "raw_data['mom5'] = raw_data['close'].pct_change(periods=5)\n",
    "\n",
    "# Volatility\n",
    "raw_data['volatility_50'] = raw_data['log_ret'].rolling(window=50, min_periods=50, center=False).std()\n",
    "raw_data['volatility_15'] = raw_data['log_ret'].rolling(window=15, min_periods=15, center=False).std()\n",
    "\n",
    "# Serial Correlation (Takes about 4 minutes)\n",
    "window_autocorr = 50\n",
    "\n",
    "raw_data['autocorr_1'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=1), raw=False)\n",
    "raw_data['autocorr_3'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=3), raw=False)\n",
    "\n",
    "# Get the various log -t returns\n",
    "raw_data['log_t1'] = raw_data['log_ret'].shift(1)\n",
    "raw_data['log_t2'] = raw_data['log_ret'].shift(2)\n",
    "raw_data['log_t5'] = raw_data['log_ret'].shift(5)\n",
    "\n",
    "# Remove look ahead bias\n",
    "raw_data = raw_data.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features at event dates\n",
    "X = raw_data\n",
    "\n",
    "# Drop unwanted columns\n",
    "try:\n",
    "    X.drop(['open', 'high', 'low', 'close', 'volume'], axis=1, inplace=True)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "X.dropna(inplace=True)\n",
    "y = labels_p['bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_idx = y.index.join(X.index).join(labels_p.index)\n",
    "X = X.loc[com_idx]\n",
    "y = y.loc[com_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary - Balance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "X_training_validation = X['2018-01-01':'2018-10-31']\n",
    "y_training_validation = y['2018-01-01':'2018-10-31']\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_training_validation, y_training_validation, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary - Fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimator = 10\n",
    "depth = 2\n",
    "c_random_state = 42\n",
    "\n",
    "# Refit a new model with best params, so we can see feature importance\n",
    "rf1 = RandomForestClassifier(max_depth=depth, n_estimators=n_estimator,\n",
    "                            criterion='entropy', random_state=c_random_state)\n",
    "\n",
    "rf1.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"['open' 'high' 'low' 'close' 'volume'] not found in axis\"\n"
     ]
    }
   ],
   "source": [
    "X = raw_data\n",
    "X.dropna(inplace=True)\n",
    "try:\n",
    "    X.drop(['open', 'high', 'low', 'close', 'volume'], axis=1, inplace=True)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predict = rf1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbar2 = dbar.loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbar2['side'] = total_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-15 17:37:31.199951 100.0% apply_pt_sl_on_t1 done after 0.1 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "pt_sl = [1, 2]\n",
    "min_ret = 0.005\n",
    "triple_barrier_events = ml.labeling.get_events(close=dbar2['close'],\n",
    "                                               t_events=cusum_events,\n",
    "                                               pt_sl=pt_sl,\n",
    "                                               target=daily_vol,\n",
    "                                               min_ret=min_ret,\n",
    "                                               num_threads=3,\n",
    "                                               vertical_barrier_times=vertical_barriers,\n",
    "                                               side_prediction=dbar2['side'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>side</th>\n",
       "      <th>t1</th>\n",
       "      <th>trgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:01:09.291</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:53.717</td>\n",
       "      <td>0.005417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:01:32.046</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:38.938</td>\n",
       "      <td>0.005706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:02:03.804</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:53.717</td>\n",
       "      <td>0.005768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:02:29.405</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:55.275</td>\n",
       "      <td>0.005546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:02:46.421</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:03:00.761</td>\n",
       "      <td>0.005789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         side                      t1      trgt\n",
       "2018-01-09 09:01:09.291  -1.0 2018-01-09 09:02:53.717  0.005417\n",
       "2018-01-09 09:01:32.046  -1.0 2018-01-09 09:02:38.938  0.005706\n",
       "2018-01-09 09:02:03.804  -1.0 2018-01-09 09:02:53.717  0.005768\n",
       "2018-01-09 09:02:29.405  -1.0 2018-01-09 09:02:55.275  0.005546\n",
       "2018-01-09 09:02:46.421  -1.0 2018-01-09 09:03:00.761  0.005789"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triple_barrier_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    2438\n",
       " 1.0    1179\n",
       "Name: side, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_m = ml.labeling.get_bins(triple_barrier_events, dbar2['close'])\n",
    "labels_m.side.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2323\n",
       "0    1294\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_m.bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels_m['bin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta - Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_idx = y.index.join(X.index).join(labels_m.index)\n",
    "X = X.loc[com_idx]\n",
    "y = y.loc[com_idx]\n",
    "labels_m = labels_m.loc[com_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "X_training_validation = X['2018-01-01':'2018-10-31']\n",
    "y_training_validation = y['2018-01-01':'2018-10-31']\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_training_validation, y_training_validation, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta - Balance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "X_training_validation = X['2018-01-01':'2018-10-31']\n",
    "y_training_validation = y['2018-01-01':'2018-10-31']\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_training_validation, y_training_validation, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1640\n",
       "0     864\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([y_train, X_train], axis=1, join='inner')\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    864\n",
       "0    864\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsample the training data to have a 50 - 50 split\n",
    "# https://elitedatascience.com/imbalanced-classes\n",
    "majority = train_df[train_df['bin'] == 0]\n",
    "minority = train_df[train_df['bin'] == 1]\n",
    "\n",
    "new_minority = resample(minority, \n",
    "                   replace=True,     # sample with replacement\n",
    "                   n_samples=majority.shape[0],    # to match majority class\n",
    "                   random_state=42)\n",
    "\n",
    "train_df = pd.concat([majority, new_minority])\n",
    "train_df = shuffle(train_df, random_state=42)\n",
    "\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta - Fit a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit a new model with best params, so we can see feature importance\n",
    "rf2 = RandomForestClassifier(max_depth=depth, n_estimators=n_estimator,\n",
    "                            criterion='entropy', random_state=c_random_state)\n",
    "\n",
    "rf2.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bet Sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finance_ml.labeling.sizes import get_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = rf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.Series(y_prob[:,1], index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>side</th>\n",
       "      <th>t1</th>\n",
       "      <th>trgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:01:09.291</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:53.717</td>\n",
       "      <td>0.005417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:01:32.046</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:38.938</td>\n",
       "      <td>0.005706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:02:03.804</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:53.717</td>\n",
       "      <td>0.005768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:02:29.405</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:02:55.275</td>\n",
       "      <td>0.005546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09 09:02:46.421</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2018-01-09 09:03:00.761</td>\n",
       "      <td>0.005789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         side                      t1      trgt\n",
       "2018-01-09 09:01:09.291  -1.0 2018-01-09 09:02:53.717  0.005417\n",
       "2018-01-09 09:01:32.046  -1.0 2018-01-09 09:02:38.938  0.005706\n",
       "2018-01-09 09:02:03.804  -1.0 2018-01-09 09:02:53.717  0.005768\n",
       "2018-01-09 09:02:29.405  -1.0 2018-01-09 09:02:55.275  0.005546\n",
       "2018-01-09 09:02:46.421  -1.0 2018-01-09 09:03:00.761  0.005789"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triple_barrier_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_size = get_signal(y_df, triple_barrier_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.803324099723\n",
      "97\n",
      "112.36573855883363\n"
     ]
    }
   ],
   "source": [
    "def betSize(w,x): \n",
    "    return x*(w+x**2)**-.5\n",
    "#——————————————————————————————————————— \n",
    "def getTPos(w,f,mP,maxPos): \n",
    "    return int(betSize(w,f-mP)*maxPos) \n",
    "#——————————————————————————————————————— \n",
    "def invPrice(f,w,m): \n",
    "    return f-m*(w/(1-m**2))**.5\n",
    "#——————————————————————————————————————— \n",
    "def limitPrice(tPos,pos,f,w,maxPos): \n",
    "    sgn=(1 if tPos>=pos else -1) \n",
    "    lP=0 \n",
    "    for j in range(abs(pos+sgn),abs(tPos+1)): \n",
    "        lP+=invPrice(f,w,j/float(maxPos))\n",
    "    lP/=tPos-pos \n",
    "    return lP\n",
    "#——————————————————————————————————————— \n",
    "def getW(x,m): \n",
    "    # 0<alpha<1 \n",
    "    return x**2*(m**-2-1)\n",
    "#——————————————————————————————————————— \n",
    "\n",
    "pos,maxPos,mP,f,wParams=0,100,100,115,{'divergence':10,'m':.95} \n",
    "# calibrate w \n",
    "w=getW(wParams['divergence'],wParams['m']) \n",
    "print(w)\n",
    "# get tPos \n",
    "tPos=getTPos(w,f,mP,maxPos) \n",
    "print(tPos)\n",
    "# limit price for order return\n",
    "lP=limitPrice(tPos,pos,f,w,maxPos) \n",
    "print(lP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afml",
   "language": "python",
   "name": "afml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
