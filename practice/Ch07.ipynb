{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/afml/venv/lib/python3.5/site-packages/pyfolio/pos.py:28: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  ' to position notionals.'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pyfolio as pf\n",
    "\n",
    "sys.path.insert(0, '/mnt/afml/ml_finance/mlfinlab')\n",
    "from mlfinlab.data_structures import imbalance_data_structures as imbar, standard_data_structures as bar\n",
    "import mlfinlab as ml\n",
    "\n",
    "sys.path.insert(0, '/mnt/afml/ml_finance/finance_ml')\n",
    "from finance_ml import sampling, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X,y,clf):\n",
    "    from sklearn import metrics\n",
    "    # The random forest model by itself\n",
    "    y_pred_rf = clf.predict_proba(X)[:, 1]\n",
    "    y_pred = clf.predict(X)\n",
    "    fpr_rf, tpr_rf, _ = metrics.roc_curve(y, y_pred_rf)\n",
    "    print(metrics.classification_report(y, y_pred))\n",
    "\n",
    "    plt.figure(figsize=(9,6))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr_rf, tpr_rf, label='clf')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def evaluate_multi(X_test, y_test, fit, n_classes=3):\n",
    "    \"\"\"\n",
    "    adapted from:\n",
    "        https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "    \"\"\"\n",
    "    from sklearn import metrics\n",
    "    \n",
    "    print(metrics.classification_report(y_test, fit.predict(X_test)))\n",
    "    \n",
    "    try:\n",
    "        y_score = fit.decision_function(X_test)\n",
    "    except:\n",
    "        y_score = fit.predict_proba(X_test)\n",
    "        \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])    \n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "    lw=2\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Multiclass Bins')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parq(fname):\n",
    "    table = pq.read_table(fname)\n",
    "    df = table.to_pandas()\n",
    "    df = df.set_index('TIMESTAMP')\n",
    "    ''' 중복된 index 제거, volume은 더해준다 '''\n",
    "    df = df.sort_values(by='TIMESTAMP')  # 중복 데이터 무시\n",
    "    df_v = df.groupby(df.index).sum()\n",
    "    df = df.loc[~df.index.duplicated(keep='first')]\n",
    "    df['V'] = df_v['V']\n",
    "    df['DV'] = df_v['DV']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'dataset/TRADE_A233740_2018.parq'\n",
    "df = load_parq(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'dataset/TRADE_A233740_2018.csv'\n",
    "bar_fname = 'dataset/DBAR_A233740_2018.csv'\n",
    "if not os.path.exists(fname):\n",
    "    df_csv = df.reset_index()[['TIMESTAMP', 'PRICE', 'V']]\n",
    "    df_csv.columns = ['date_time', 'price', 'volume']\n",
    "    df_csv['price'] = df_csv['price'].astype('float')\n",
    "    df_csv.to_csv(fname, index=False)\n",
    "    \n",
    "if os.path.exists(bar_fname):\n",
    "    dbar = pd.read_csv(bar_fname, index_col='date_time')\n",
    "    dbar.index = pd.to_datetime(dbar.index)\n",
    "else:\n",
    "    dbar = bar.get_dollar_bars(fname, threshold=1e8)\n",
    "    dbar.index = pd.to_datetime(dbar.index)\n",
    "    dbar.to_csv(bar_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp('2018-01-03 09:00:21.481000')\n"
     ]
    }
   ],
   "source": [
    "# Compute daily volatility\n",
    "daily_vol = ml.util.get_daily_vol(close=dbar['close'], lookback=50)\n",
    "\n",
    "# Apply Symmetric CUSUM Filter and get timestamps for events\n",
    "# Note: Only the CUSUM filter needs a point estimate for volatility\n",
    "daily_vol_mean = daily_vol.rolling(10000).mean()\n",
    "cusum_events = ml.filters.cusum_filter(dbar['close'], daily_vol_mean=daily_vol_mean)\n",
    "\n",
    "# Compute vertical barrier\n",
    "vertical_barriers = ml.labeling.add_vertical_barrier(t_events=cusum_events, close=dbar['close'], num_days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-07 16:12:17.435514 100.0% apply_pt_sl_on_t1 done after 0.1 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "pt_sl = [1, 1]\n",
    "min_ret = 0.005\n",
    "triple_barrier_events = ml.labeling.get_events(close=dbar['close'],\n",
    "                                               t_events=cusum_events,\n",
    "                                               pt_sl=pt_sl,\n",
    "                                               target=daily_vol,\n",
    "                                               min_ret=min_ret,\n",
    "                                               num_threads=3,\n",
    "                                               vertical_barrier_times=vertical_barriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_p = ml.labeling.get_bins(triple_barrier_events, dbar['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = dbar.copy()\n",
    "\n",
    "# Log Returns\n",
    "raw_data['log_ret'] = np.log(raw_data['close']).diff()\n",
    "\n",
    "# Momentum\n",
    "raw_data['mom1'] = raw_data['close'].pct_change(periods=1)\n",
    "raw_data['mom2'] = raw_data['close'].pct_change(periods=2)\n",
    "raw_data['mom5'] = raw_data['close'].pct_change(periods=5)\n",
    "\n",
    "# Volatility\n",
    "raw_data['volatility_50'] = raw_data['log_ret'].rolling(window=50, min_periods=50, center=False).std()\n",
    "raw_data['volatility_15'] = raw_data['log_ret'].rolling(window=15, min_periods=15, center=False).std()\n",
    "\n",
    "# Serial Correlation (Takes about 4 minutes)\n",
    "window_autocorr = 50\n",
    "\n",
    "raw_data['autocorr_1'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=1), raw=False)\n",
    "raw_data['autocorr_3'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=3), raw=False)\n",
    "\n",
    "# Get the various log -t returns\n",
    "raw_data['log_t1'] = raw_data['log_ret'].shift(1)\n",
    "raw_data['log_t2'] = raw_data['log_ret'].shift(2)\n",
    "raw_data['log_t5'] = raw_data['log_ret'].shift(5)\n",
    "\n",
    "# Remove look ahead bias\n",
    "raw_data = raw_data.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"['open' 'high' 'low' 'close' 'volume'] not found in axis\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/afml/venv/lib/python3.5/site-packages/pandas/core/indexing.py:1017: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return getattr(section, self.name)[new_key]\n"
     ]
    }
   ],
   "source": [
    "# Get features at event dates\n",
    "X = raw_data\n",
    "\n",
    "# Drop unwanted columns\n",
    "try:\n",
    "    X.drop(['open', 'high', 'low', 'close', 'volume'], axis=1, inplace=True)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "y = labels_p.loc[X.index,'bin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.dropna()\n",
    "X = X.dropna()\n",
    "com_idx = y.index.join(X.index).join(labels_p.index)\n",
    "X = X.loc[com_idx]\n",
    "y = y.loc[com_idx]\n",
    "labels_p = labels_p.loc[com_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection._split import _BaseKFold\n",
    "import time\n",
    "\n",
    "\n",
    "def get_train_times(t1, test_times):\n",
    "    trn = t1.copy(deep=True)\n",
    "    for i, j in test_times.iteritems():\n",
    "        df0 = trn[(i <= trn.index) & (trn.index <= j)].index\n",
    "        df1 = trn[(i <= trn) & (trn <= j)].index\n",
    "        df2 = trn[(trn.index <= i) & (j <= trn)].index\n",
    "        trn = trn.drop(df0.union(df1.union(df2)))\n",
    "    return trn\n",
    "\n",
    "\n",
    "class PurgedKFold(_BaseKFold):\n",
    "    def __init__(self, n_splits=3, t1=None, pct_embargo=0., purging=True):\n",
    "        if not isinstance(t1, pd.Series):\n",
    "            raise ValueError('Label through dates must be a pd.Series')\n",
    "        super(PurgedKFold, self).__init__(n_splits=n_splits, shuffle=False,\n",
    "                                          random_state=None)\n",
    "        self.t1 = t1\n",
    "        self.pct_embargo = pct_embargo\n",
    "        self.purging = purging\n",
    "        \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        if (X.index == self.t1.index).sum() != len(self.t1):\n",
    "            raise ValueError('X and t1 must have the same index')\n",
    "        indices = np.arange(X.shape[0])\n",
    "        # Embargo width\n",
    "        embg_size = int(X.shape[0] * self.pct_embargo)\n",
    "        test_ranges = [(i[0], i[-1] + 1) for i in np.array_split(indices, self.n_splits)]\n",
    "        for st, end in test_ranges:\n",
    "            # Test data\n",
    "            test_indices = indices[st:end]\n",
    "            # Training data prior to test data\n",
    "            t0 = self.t1.index[st]\n",
    "            train_indices = self.t1.index.searchsorted(self.t1[self.t1 <= t0].index)\n",
    "            # Add training data after test data\n",
    "            max_t1_idx = self.t1.index.searchsorted(self.t1[test_indices].max())\n",
    "            if max_t1_idx < X.shape[0]:\n",
    "                train_indices = np.concatenate((train_indices, indices[max_t1_idx + embg_size:]))\n",
    "            # Purging\n",
    "            if self.purging:\n",
    "                train_t1 = t1.iloc[train_indices]\n",
    "                test_t1 = t1.iloc[test_indices]\n",
    "                train_t1 = get_train_times(train_t1, test_t1)\n",
    "                train_indices = self.t1.index.searchsorted(train_t1.index)\n",
    "            yield train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from finance_ml.sampling import get_sample_tw, get_num_co_events\n",
    "\n",
    "def cv_score(clf, X, y, sample_weight=None, scoring='neg_log_loss',\n",
    "             t1=None, n_splits=3, cv_gen=None, pct_embargo=0., purging=False):\n",
    "    if scoring not in ['neg_log_loss', 'accuracy']:\n",
    "        raise Exception('Wrong scoring method')\n",
    "    if cv_gen is None:\n",
    "        cv_gen = PurgedKFold(n_splits=n_splits, t1=t1,\n",
    "                             pct_embargo=pct_embargo,\n",
    "                             purging=purging)\n",
    "    scores = []\n",
    "    for train, test in cv_gen.split(X=X):\n",
    "        train_params = dict()\n",
    "        test_params = dict()\n",
    "        # Sample weight is an optional parameter\n",
    "        if sample_weight is not None:\n",
    "            train_params['sample_weight'] = sample_weight.iloc[train].values\n",
    "            test_params['sample_weight'] = sample_weight.iloc[test].values\n",
    "        clf_ = clf.fit(X=X.iloc[train, :], y=y.iloc[train], **train_params)\n",
    "        # Scoring\n",
    "        if scoring == 'neg_log_loss':\n",
    "            prob = clf_.predict_proba(X.iloc[test, :])\n",
    "            score_ = -log_loss(y.iloc[test], prob, labels=clf.classes_, **test_params)\n",
    "        else:\n",
    "            pred = clf_.predict(X.iloc[test, :])\n",
    "            score_ = accuracy_score(y.iloc[test], pred, **test_params)\n",
    "        scores.append(score_)\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = triple_barrier_events['t1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/afml/venv/lib/python3.5/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0680268690194796 0.005584395882292894\n",
      "CPU times: user 22.9 s, sys: 0 ns, total: 22.9 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "t1_ = t1.loc[X.index]\n",
    "\n",
    "scores = []\n",
    "for _ in range(100):\n",
    "    scores_ = cv_score(clf, X, y, pct_embargo=0.01, t1=t1_, purging=False)\n",
    "    scores.append(np.mean(scores_))\n",
    "print(np.mean(scores), np.var(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.05369050547682 0.006664855616556574\n",
      "CPU times: user 23.2 s, sys: 12 ms, total: 23.2 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = []\n",
    "for _ in range(100):\n",
    "    scores_ = cv_score(clf, X, y, pct_embargo=0., t1=t1_, purging=False)\n",
    "    scores.append(np.mean(scores_))\n",
    "print(np.mean(scores), np.var(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Sample Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-07 16:31:25.460185 100.0% mp_num_co_events done after 0.04 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "n_co_events = get_num_co_events(dbar['close'].index, t1, 2)\n",
    "sample_weight = get_sample_tw(t1, n_co_events, triple_barrier_events.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7865575522045418 0.0055055586350653\n",
      "CPU times: user 22.2 s, sys: 8 ms, total: 22.2 s\n",
      "Wall time: 22.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = []\n",
    "for _ in range(100):\n",
    "    scores_ = cv_score(clf, X, y, sample_weight=sample_weight,\n",
    "                       pct_embargo=0.01, t1=t1_, purging=False)\n",
    "    scores.append(np.mean(scores_))\n",
    "print(np.mean(scores), np.var(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7609021277346542 0.003260393881464174\n",
      "CPU times: user 22.4 s, sys: 4 ms, total: 22.4 s\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = []\n",
    "for _ in range(100):\n",
    "    scores_ = cv_score(clf, X, y, sample_weight=sample_weight,\n",
    "                       pct_embargo=0., t1=t1_, purging=False)\n",
    "    scores.append(np.mean(scores_))\n",
    "print(np.mean(scores), np.var(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afml",
   "language": "python",
   "name": "afml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
